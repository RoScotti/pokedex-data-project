# pokÃ©dex-data-project ğŸ—ï¸ğŸ”
A complete data pipeline for ingesting, transforming, and storing PokÃ©mon data using Python, Terraform, Snowflake, and Airflow.

## ğŸ“Œ Project Overview

This project demonstrates a real-world data engineering workflow, simulating how businesses handle large-scale data processing. The pipeline extracts data from the PokÃ©mon API, processes and transforms it, and loads it into Snowflake, all while following industry best practices for scalability, automation, and observability.

## ğŸ”§ Tech Stack

- **Python** ğŸ â†’ Data extraction & transformation
- **Terraform** ğŸ—ï¸ â†’ Infrastructure as Code (Snowflake setup)
- **Snowflake** â„ï¸ â†’ Cloud data warehouse
- **Airflow** ğŸ”„ â†’ Data pipeline orchestration
- **GitHub** ğŸ› ï¸ â†’ Version control & collaboration
- **VS Code** ğŸ’» â†’ Development environment

## ğŸ“Š Pipeline Workflow

- 1ï¸âƒ£ **Extract** â†’ Fetch PokÃ©mon data from the API (species, evolutions, types, stats).
- 2ï¸âƒ£ **Transform** â†’ Clean & structure the data (group evolutions, categorise by type, format timestamps).
- 3ï¸âƒ£ **Load** â†’ Store processed data in Snowflake for analytics.
- 4ï¸âƒ£ **Orchestrate** â†’ Automate the pipeline using Apache Airflow.

## ğŸš€ Key Features

- âœ… **Infrastructure as Code (IaC)** â†’ Terraform automates Snowflake setup.
- âœ… **Automated Pipelines** â†’ Airflow schedules and monitors the ETL process.
- âœ… **Cloud-Based Storage** â†’ Snowflake ensures fast, scalable data storage.
- âœ… **Real-World Use Case** â†’ Simulates how data engineers process & store external API data.
